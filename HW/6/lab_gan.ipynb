{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "lab_gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEENfR8AFTXa",
        "colab_type": "text"
      },
      "source": [
        "# Генеративно-состязательные сети (Generative Adversarial Networks)\n",
        "\n",
        "В задании предлагается реализовать GAN, обучить её на MNIST, оценить правдоподобие и сделать выводы.\n",
        "\n",
        "Необходимая теория приведена ниже.\n",
        "\n",
        "Актуальная версия доступна по адресу https://github.com/nadiinchi/dl_labs/blob/master/lab_gan.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUapZz5uFTXc",
        "colab_type": "text"
      },
      "source": [
        "## Постановка задачи\n",
        "Дана выборка независимых одинаково распределенных величин из истинного распределения $x_i \\sim p_d(x)$, $i = 1, \\dots, N$.\n",
        "\n",
        "Задача - построить вероятностную модель $p_\\theta(x)$ истинного распределения $p_d(x)$.\n",
        "\n",
        "Распределение $p_\\theta(x)$ должно позволять как оценить плотность вероятности для данного объекта $x$, так и сэмплировать $x \\sim p_\\theta(x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ4015ZZFTXd",
        "colab_type": "text"
      },
      "source": [
        "## Вероятностная модель\n",
        "$z \\in \\mathbb{R}^d$ - локальная латентная переменная, т. е. своя для каждого объекта $x \\in \\mathbb{R}^D$.\n",
        "\n",
        "Генеративный процесс вариационного автокодировщика:\n",
        "1. Сэмплируем $z \\sim p(z)$.\n",
        "2. $x = G_\\theta(z)$.\n",
        "\n",
        "Параметры преобразования $G_\\theta(z)$ задаются нейросетью с весами $\\theta$, получающей на вход вектор $z$.\n",
        "\n",
        "Индуцированная генеративным процессом плотность вероятности объекта $x$:\n",
        "\n",
        "$$p_\\theta(x) = \\mathbb{E}_{z \\sim p(z)} \\delta(x = G(z))$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RatASgVEFTXe",
        "colab_type": "text"
      },
      "source": [
        "## Оценка логарифма правдоподобия\n",
        "Для оценки логарифма правдоподобия используется метод Парзеновского окна/ядерного сглаживания (англ. Kernel Density Estimation/Parzen–Rosenblatt window method). Концептуально он заключается в том, что мы сглаживаем модельное распределение, и по этому сглаженному распределению вычисляем правдоподобие модели.\n",
        "\n",
        "$$p_\\theta(x) = \\mathbb{E}_{z \\sim p(z)} \\delta(x = G(z)) \\approx \\frac{1}{Mh^D}\\sum_{i=1}^M K\\left(\\frac{x - G_\\theta(z_i)}{h}\\right)$$\n",
        "\n",
        "Здесь $K(x)$ - любое распределение, а $h$ - ширина окна. Тогда выполняется\n",
        "\n",
        "$$\\mathbb{E}_{x \\sim p_d} \\log p_\\theta(x) \\approx  \\frac{1}{N}\\sum_{i=1}^{N} \\log \\frac{1}{Mh^D}\\sum_{j=1}^M K\\left(\\frac{x_i - G_\\theta(z_j)}{h}\\right)$$\n",
        "\n",
        "В генеративно-состязательных сетях для оценки правдоподобия используется стандартное нормальное распределение $K(x) = N(x | 0, I)$. Тогда получаем\n",
        "\n",
        "$$\\mathbb{E}_{x \\sim p_d} \\log p_\\theta(x) \\approx  \\frac{1}{N}\\sum_{i=1}^{N} \\log \\frac{1}{M}\\sum_{j=1}^M \\prod_{k=1}^D\\frac{1}{\\sqrt{2 \\pi} \\sigma}\\exp\\left(-\\frac{(x_{i,k} - G(z_j)_k)^2}{2\\sigma^2}\\right)$$\n",
        "\n",
        "Коэффициент $\\sigma$ настраивается на валидационной выборке и с его помощью считается правдоподобие тестовой выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4ICfWpIFTXf",
        "colab_type": "text"
      },
      "source": [
        "### Загрузка, нормировка и визуалиация данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCIAuk81FTXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WzkLZrAFTXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = MNIST('mnist', download=True, train=True)\n",
        "train_data = TensorDataset(data.train_data.view(-1, 28 * 28).float() / 255)\n",
        "data = MNIST('mnist', download=True, train=False)\n",
        "test_data_raw = TensorDataset(data.test_data.view(-1, 28 * 28).float() / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er3-NKyRFTXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digit_size = 14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTLtfvvOFTXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.tensors = (nn.AvgPool2d(2, 2)(train_data.tensors[0].view(-1, 28, 28)).data.view(-1, 196), )\n",
        "test_data_raw.tensors = (nn.AvgPool2d(2, 2)(test_data_raw.tensors[0].view(-1, 28, 28)).data.view(-1, 196), )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eavR9CKFTXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_data = TensorDataset(test_data_raw.tensors[0][:5000])\n",
        "test_data = TensorDataset(test_data_raw.tensors[0][5000:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGS0PsiQFTXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_images(x):\n",
        "    plt.figure(figsize=(12, 12 / 10 * (x.shape[0] // 10 + 1)))\n",
        "    x = x.view(-1, digit_size, digit_size)\n",
        "    for i in range(x.shape[0]):\n",
        "        plt.subplot(x.shape[0] // 10 + 1, 10, i + 1)\n",
        "        plt.imshow(x.data[i].numpy(), cmap='Greys_r', vmin=0, vmax=1, interpolation='lanczos')\n",
        "        plt.axis('off')\n",
        "\n",
        "show_images(train_data[:10][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKJ0HSkcFTX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 15\n",
        "\n",
        "from scipy.stats import norm\n",
        "import numpy as np\n",
        "\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "def draw_manifold(generator):\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    for i, yi in enumerate(grid_x):\n",
        "        for j, xi in enumerate(grid_y):\n",
        "            z_sample = np.array([[xi, yi]])\n",
        "\n",
        "            x_decoded = generator(z_sample)\n",
        "            digit = x_decoded\n",
        "            figure[i * digit_size: (i + 1) * digit_size,\n",
        "                   j * digit_size: (j + 1) * digit_size] = digit\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(figure, cmap='Greys_r', vmin=0, vmax=1, interpolation='lanczos')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aknj1zPoFTX4",
        "colab_type": "text"
      },
      "source": [
        "### Функции и классы, описывающие модель и процесс её обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCArEfJ5FTX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        \"\"\"\n",
        "        Запоминает размерности, в которые при проходе\n",
        "        вперед будут переводиться все объекты.\n",
        "        Например,\n",
        "            input = torch.zeros(100, 196)\n",
        "            reshape_layer = Reshape(1, 14, 14)\n",
        "            reshape_layer(input)\n",
        "        возвращает тензор размерности (100, 1, 14, 14).\n",
        "            input = torch.zeros(100, 1, 14, 14)\n",
        "            reshape_layer = Reshape(-1)\n",
        "            reshape_layer(input)\n",
        "        наоборот вернет тензор размерности (100, 196).\n",
        "        \"\"\"\n",
        "        super(type(self), self).__init__()\n",
        "        self.dims = args\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Возвращает тензор с измененными размерностями объектов.\n",
        "        Вход: input, FloatTensor.\n",
        "        Возвращаемое значение: FloatTensor.\n",
        "        \"\"\"\n",
        "        return input.view(input.size(0), *self.dims)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5HTXsvXFTX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAN(nn.Module):\n",
        "    def __init__(self, d):\n",
        "        \"\"\"\n",
        "        Инициализирует веса модели.\n",
        "        Вход: d, int - размерность латентного пространства.\n",
        "        Вход: D, int - размерность пространства объектов.\n",
        "        \"\"\"\n",
        "        super(type(self), self).__init__()\n",
        "        self.d = d\n",
        "\n",
        "        # Можно пробовать другие архитектуры: как более сложные\n",
        "        # сверточные, так и более простые, например, полносвязные.\n",
        "        # Однако желательно обучить хотя бы одну сверточную модель.\n",
        "        self.discriminator = nn.Sequential(\n",
        "            Reshape(1, 14, 14),\n",
        "            nn.Conv2d(1, 64, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 32, 3, 2, 0, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 16, 3, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(),\n",
        "            Reshape(-1),\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.generator = nn.Sequential(\n",
        "            Reshape(self.d, 1, 1),\n",
        "            nn.ConvTranspose2d(self.d, 128, 4, 1, 0, 0, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 1, 3, 2, 1, 1, bias=False),\n",
        "            Reshape(-1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def generate_noise(self, num_samples):\n",
        "        \"\"\"\n",
        "        Генерирует сэмплы из априорного распределения на z.\n",
        "        Вход: num_samples, int - число сэмплов, которые надо сгененрировать.\n",
        "        Возвращаемое значение: Tensor, матрица размера num_samples x d.\n",
        "        \"\"\"\n",
        "        z = torch.normal(mean=0., std=1., size=(num_samples, self.d))\n",
        "\n",
        "        if next(self.parameters()).is_cuda:\n",
        "            z = z.cuda()\n",
        "        return z\n",
        "\n",
        "    def generate_samples(self, num_samples):\n",
        "        \"\"\"\n",
        "        Генерирует сэмплы из индуцируемого моделью распределения на объекты x.\n",
        "        Вход: num_samples, int - число сэмплов, которые надо сгененрировать.\n",
        "        Возвращаемое значение: Tensor, матрица размера num_samples x D.\n",
        "        \"\"\"\n",
        "        noise = self.generate_noise(num_samples)\n",
        "        samples = self.generator(noise)\n",
        "        return samples\n",
        "\n",
        "    def discriminator_loss(self, batch):\n",
        "        \"\"\"\n",
        "        Вычисляет значение функции потерь дискриминатора на данном батче.\n",
        "        Возвращаемая оценка должна быть дифференцируема по параметрам модели (!).\n",
        "        Вход: batch, FloatTensor - матрица объектов размера n x D.\n",
        "        Возвращаемое значение: Tensor, скаляр - значение функции потерь\n",
        "        дискриминатора на данном батче.\n",
        "        \"\"\"\n",
        "        half_samples = batch.shape[0]\n",
        "        generated_samples = self.generate_samples(half_samples)\n",
        "        predicted_probs_gt = self.discriminator(batch)\n",
        "        predicted_probs_gen = self.discriminator(generated_samples)\n",
        "        ones = torch.ones_like(predicted_probs_gt)\n",
        "        zeros = torch.zeros_like(predicted_probs_gen)\n",
        "\n",
        "        loss = F.binary_cross_entropy(predicted_probs_gt, zeros) + \\\n",
        "               F.binary_cross_entropy(predicted_probs_gen, ones)\n",
        "        return loss * 0.5\n",
        "\n",
        "    def generator_loss(self, batch_size):\n",
        "        \"\"\"\n",
        "        Вычисляет значение функции потерь генератора на данном батче.\n",
        "        Возвращаемая оценка должна быть дифференцируема по параметрам модели (!).\n",
        "        # Вход: batch, FloatTensor - матрица объектов размера n x D.\n",
        "        Вход: batch_size - число объектов n.        \n",
        "        Возвращаемое значение: Tensor, скаляр - значение функции потерь\n",
        "        генератора на данном батче.\n",
        "        \"\"\"\n",
        "        generated_samples = self.generate_samples(batch_size)\n",
        "        predicted_probs_gen = self.discriminator(generated_samples)\n",
        "        zeros = torch.zeros_like(predicted_probs_gen)\n",
        "        ones = torch.ones_like(predicted_probs_gen)\n",
        "        loss = F.binary_cross_entropy(predicted_probs_gen, zeros)\n",
        "\n",
        "        return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRSfgxGPFTYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_mean_exp(mtx):\n",
        "    \"\"\"\n",
        "    Возвращает логарифм среднего по каждому столбцу от экспоненты данной матрицы.\n",
        "    Подсказка: не забывайте про вычислительную стабильность!\n",
        "    Вход: mtx, Tensor - матрица размера n x k.\n",
        "    Возвращаемое значение: Tensor, вектор длины n.\n",
        "    \"\"\"\n",
        "    eps = 1e-10\n",
        "    mtx_max = mtx.max()\n",
        "    tmp = torch.exp(mtx - mtx_max)\n",
        "    s = torch.mean(tmp + eps)\n",
        "    return torch.log(s) + mtx_max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFzPF8bOFTYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_likelihood(gen_set, validation_set, test_set):\n",
        "    \"\"\"\n",
        "    Возвращает оценку логарифма правдоподобия модели GAN методом\n",
        "    Парзеновского окна со стандартным нормальным ядром.\n",
        "    Подсказка: sigma должна настраиваться по валидационной выборке, а\n",
        "    правдоподобие считаться по тестовой.\n",
        "    Подсказка: вместо sigma можно настраивать log_sigma.\n",
        "    Подсказка: для настройки sigma допустимо использовать как перебор по сетке,\n",
        "    так и другие методы опимизации.\n",
        "    Вход: generated_set - сэмплы из генеративной модели.\n",
        "    Вход: validation_set - валидационная выборка.\n",
        "    Вход: test_set - тестовая выборка.\n",
        "    Возвращаемое значение: float (не Tensor!) - оценка логарифма правдоподобия.\n",
        "    \"\"\"\n",
        "    # ваш код здесь\n",
        "    # samples_gen, d = generated_set.shape   # M\n",
        "    # samples_val, _ = validation_set.shape  # N\n",
        "    # samples_test, _ = test_set.shape       # N2\n",
        "    \n",
        "    def count_ml(gen_set, val_set, sigma):\n",
        "        res = 0\n",
        "        samples, d = val_set.shape\n",
        "        log_denom = np.log(np.sqrt(2 * np.pi) * sigma)\n",
        "        for x_i in val_set.split(1, dim=0):\n",
        "            mat_of_diffs = -((gen_set - x_i) / (2 * sigma)) ** 2\n",
        "            log_sum = mat_of_diffs.sum(dim=-1)\n",
        "            log_sum -= log_denom * d\n",
        "            res += log_mean_exp(log_sum)\n",
        "        return res / samples\n",
        "\n",
        "    sigmas = np.linspace(0.01, 1, 10)\n",
        "    ml_sigma = np.array([count_ml(gen_set, validation_set, sigma) for sigma in sigmas])\n",
        "    \n",
        "    sigmas_am = ml_sigma.argmax()\n",
        "    sigma = sigmas[sigmas_am]\n",
        "    # print(f\"best_sigma: {sigma}\")\n",
        "    \n",
        "    lse = count_ml(gen_set, test_set, sigma)\n",
        "    return lse.cpu().detach().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txBbhqVpFTYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_many_samples(model, num_samples, batch_size):\n",
        "    size = 0\n",
        "    res = []\n",
        "    while size < num_samples:\n",
        "        res.append(model.generate_samples(min(batch_size, num_samples - size)))\n",
        "        size += batch_size\n",
        "    return torch.cat(res, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJptS6aLFTYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, num_epochs=100, k=50):\n",
        "    \"\"\"\n",
        "    Обучает модель.\n",
        "    Вход: model, Module - объект, модель.\n",
        "    У этого объекта должна быть функция batch_loss от batch - FloatTensor и K - int,\n",
        "    возвращающая скаляр Variable - функцию потерь на батче, которая должна быть\n",
        "    оптимизирована.\n",
        "    Вход: k, int - число итераций оптимизации дискриминатора на итерацию оптимизации\n",
        "    генератора.\n",
        "    Вход: batch_size, int.\n",
        "    Вход: num_epochs, int.\n",
        "    Вход: learning_rate, float.\n",
        "    Возвращаемое значение: словарь с полями 'model' - обученная модель,\n",
        "    'generator_losses' - список значений функции потерь генератора,\n",
        "    'discriminator_losses' - список значений функции потерь дискриминатора.\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "    model.train()\n",
        "\n",
        "    # возможно, нужно подобрать другие параметры, чтобы модель обучилась\n",
        "    batch_size = 64\n",
        "    learning_rate = 2e-4\n",
        "\n",
        "    # возможно, нужно использовать другие методы оптимизации или параметры методов оптимизации,\n",
        "    # чтобы модель обучилась\n",
        "    gd_generator = optim.Adam(model.generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    gd_discriminator = optim.RMSprop(model.discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    total_batches = len(dataloader)\n",
        "\n",
        "    generator_losses = [0]\n",
        "    discriminator_losses = [0]\n",
        "    log_likelihoods = []\n",
        "\n",
        "    generated_samples = generate_many_samples(model, 512, batch_size).detach()\n",
        "    valid_samples = valid_data[np.random.choice(len(valid_data), 512, False)][0]\n",
        "    valid_samples = valid_samples.to(next(model.parameters()).device)\n",
        "    test_samples = test_data[np.random.choice(len(test_data), 512, False)][0]\n",
        "    test_samples = test_samples.to(next(model.parameters()).device)\n",
        "    ll = log_likelihood(generated_samples, valid_samples, test_samples)\n",
        "    log_likelihoods.append(ll)\n",
        "    print('Log-likelihood', ll, flush=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (batch, ) in enumerate(dataloader):\n",
        "            if torch.cuda.is_available():\n",
        "                batch = batch.cuda()\n",
        "\n",
        "            # ваш код здесь!\n",
        "            # разрешается менять код этой функции для реализации\n",
        "            # более сложных процедур обучения или ускорения обучения\n",
        "\n",
        "            model.discriminator.zero_grad()\n",
        "            discriminator_loss = model.discriminator_loss(batch)\n",
        "            discriminator_loss.backward()\n",
        "            gd_discriminator.step()\n",
        "            \n",
        "            gd_generator.zero_grad()\n",
        "            generator_loss = model.generator_loss(batch_size)\n",
        "            generator_loss.backward()\n",
        "            gd_generator.step()\n",
        "\n",
        "            # if (i + 1) % k == 0:\n",
        "            #     pass\n",
        "            #     model.generator.zero_grad()\n",
        "            #     generator_loss = model.generator_loss(batch.shape[0])\n",
        "            #     generator_loss = model.generator_loss(batch_size)\n",
        "            #     generator_losses.append(float(generator_loss))\n",
        "            #     generator_loss.backward()\n",
        "            #     gd_generator.step()\n",
        "\n",
        "\n",
        "            # не забудьте корректно сохранить статистику\n",
        "            generator_losses.append(float(generator_loss))\n",
        "            discriminator_losses.append(float(discriminator_loss))\n",
        "\n",
        "            if (i + 1) % 100 == 0:\n",
        "                print('\\rEpoch:', epoch, 'G_loss:', generator_losses[-1],\n",
        "                      'D_loss:', discriminator_losses[-1],\n",
        "                      'Batch', i + 1, 'of', total_batches,\n",
        "                      ' ' * 10, end='', flush=True)\n",
        "        print(flush=True)\n",
        "        generated_samples = generate_many_samples(model, 512, batch_size).detach()\n",
        "        valid_samples = valid_data[np.random.choice(len(valid_data), 512, False)][0]\n",
        "        valid_samples = valid_samples.to(next(model.parameters()).device)\n",
        "        test_samples = test_data[np.random.choice(len(test_data), 512, False)][0]\n",
        "        test_samples = test_samples.to(next(model.parameters()).device)\n",
        "        ll = log_likelihood(generated_samples, valid_samples, test_samples)\n",
        "        log_likelihoods.append(ll)\n",
        "        print('Log-likelihood', ll, flush=True)\n",
        "\n",
        "    return {\n",
        "        'model': model.cpu(),\n",
        "        'generator_losses': generator_losses,\n",
        "        'discriminator_losses': discriminator_losses,\n",
        "        'log_likelihoods': log_likelihoods\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybPaLxkLFTYM",
        "colab_type": "text"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te1G3919FTYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g10 = GAN(10)\n",
        "# возможно, для обучения модели достаточно/требуется другое число эпох\n",
        "%time gan_model_d10 = train_model(g10, num_epochs=30, k=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCGUt6nyFTYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g100 = GAN(100)\n",
        "# возможно, для обучения модели достаточно/требуется другое число эпох\n",
        "%time gan_model_d100 = train_model(g100, num_epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4hR6AejFTYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Подсказка: обучать GANs с скрытой размерностью 2 непросто,\n",
        "# для этого требуется очень аккуратно подобрать хаки/процесс обучения/\n",
        "# /архитектуру модели/инициализацию.\n",
        "# Если не получается сразу, стоит обучить GANs с бОльшей скрытой размерностью,\n",
        "# а затем вернуться к этой ячейке.\n",
        "g2 = GAN(2)\n",
        "# возможно, для обучения модели достаточно/требуется другое число эпох\n",
        "%time gan_model_d2 = train_model(g2, num_epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cw5eByFFTYX",
        "colab_type": "text"
      },
      "source": [
        "### Анализ результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZzUz8B7FTYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_manifold_gan(model):\n",
        "    generator = lambda z: model.generator(torch.from_numpy(z).float()).view(digit_size, digit_size).data.numpy()\n",
        "    return draw_manifold(generator)\n",
        "\n",
        "draw_manifold_gan(gan_model_d2['model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8A3soIaFTYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_images(gan_model_d2['model'].generate_samples(40))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZjRJvOFTYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_images(gan_model_d10['model'].generate_samples(40))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoGnVYXuFTYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_images(gan_model_d100['model'].generate_samples(40))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7uVUyc9FTYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "for label, name, model in [\n",
        "    ('$d = 2$, D_loss', 'discriminator_losses', gan_model_d2),\n",
        "    ('$d = 2$, G_loss', 'generator_losses', gan_model_d2),\n",
        "]:\n",
        "    data = model[name]\n",
        "    x_labels = (1 + np.arange(len(data))) / len(data) * 100\n",
        "    plt.plot(x_labels, data, label=label)\n",
        "plt.xlabel('Epoch')\n",
        "plt.xlim(xmin=0.01, xmax=x_labels[-1])\n",
        "plt.xscale('log')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDYw39VcFTYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "for label, name, model in [\n",
        "    ('$d = 10$, D_loss', 'discriminator_losses', gan_model_d10),\n",
        "    ('$d = 10$, G_loss', 'generator_losses', gan_model_d10),\n",
        "]:\n",
        "    data = model[name]\n",
        "    x_labels = (1 + np.arange(len(data))) / len(data) * 100\n",
        "    plt.plot(x_labels, data, label=label)\n",
        "plt.xlabel('Epoch')\n",
        "plt.xlim(xmin=0.01, xmax=x_labels[-1])\n",
        "plt.xscale('log')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOJBw1YeFTYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "for label, name, model in [\n",
        "    ('$d = 100$, D_loss', 'discriminator_losses', gan_model_d100),\n",
        "    ('$d = 100$, G_loss', 'generator_losses', gan_model_d100),\n",
        "]:\n",
        "    data = model[name]\n",
        "    x_labels = (1 + np.arange(len(data))) / len(data) * 100\n",
        "    plt.plot(x_labels, data, label=label)\n",
        "plt.xlabel('Epoch')\n",
        "plt.xlim(xmin=0.01, xmax=x_labels[-1])\n",
        "plt.xscale('log')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5sib6yHFTYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_samples = generate_many_samples(gan_model_d2['model'], 8192, 64).detach()\n",
        "%time log_likelihood(generated_samples, valid_data.tensors[0], test_data.tensors[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8RtUcPHFTYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_samples = generate_many_samples(gan_model_d10['model'], 8192, 64).detach()\n",
        "%time log_likelihood(generated_samples, valid_data.tensors[0], test_data.tensors[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGuJMMKFTY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_samples = generate_many_samples(gan_model_d100['model'], 8192, 64).detach()\n",
        "%time log_likelihood(generated_samples, valid_data.tensors[0], test_data.tensors[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mghuo6OQFTY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9, 6))\n",
        "for label, name, model in [\n",
        "    ('$d = 2$, log-likelihoods', 'log_likelihoods', gan_model_d2),\n",
        "    ('$d = 10$, log-likelihoods', 'log_likelihoods', gan_model_d10),\n",
        "    ('$d = 100$, log-likelihoods', 'log_likelihoods', gan_model_d100),\n",
        "]:\n",
        "    data = model[name]\n",
        "    x_labels = np.arange(len(data))\n",
        "    plt.plot(x_labels, data, label=label)\n",
        "plt.xlabel('Epoch')\n",
        "plt.xlim(xmin=0.0, xmax=x_labels[-1])\n",
        "plt.ylabel('Log-likelihood estimation')\n",
        "plt.legend()\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "o14P61fuFTY6",
        "colab_type": "text"
      },
      "source": [
        "## Выводы\n",
        "Место для ваших выводов, наблюдений, гипотез."
      ]
    }
  ]
}